{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPThYSNOEYWjKgnanUpsAPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadiyaArfa/Sentiment_Analysis_for_Twitter_data/blob/main/Sentiment_Analysis_for_Twitter_data_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Title:** **Sentiment Analysis on Twitter Data Using Deep Learning**\n",
        "\n",
        "**Objective:**\n",
        "To build a robust Deep Learning-based sentiment analysis model capable of accurately categorizing tweets into different sentiment classes (positive, negative, neutral). The model will leverage Natural Language Processing (NLP) techniques and Deep Learning architectures to understand and predict sentiments from text data.\n"
      ],
      "metadata": {
        "id": "KFZljemnI_Mb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and Exploration:"
      ],
      "metadata": {
        "id": "r9aYaoHg9wxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Byy6-70T9zMB"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Twitter data\n",
        "data = pd.read_csv('/Twitter- Project 1.csv',encoding = 'ISO-8859-1')\n",
        "# Explore the data\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "print(data['Sentiment'].value_counts())\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGf5fl0kBMSX",
        "outputId": "4870be91-6841-4b8b-b4e8-b67c3352a037"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Tweet Text Sentiment  \\\n",
            "0  Our team is excited to introduce our latest pr...  Positive   \n",
            "1  We apologize for the inconvenience caused by o...  Negative   \n",
            "2  Neutral on this matter, awaiting further updat...   Neutral   \n",
            "3  We're grateful for the continuous support from...  Positive   \n",
            "4  Disappointed to announce the delay in the ship...  Negative   \n",
            "\n",
            "             Timestamp         User  \n",
            "0   2023-11-18 8:45:00  @CompanyXYZ  \n",
            "1   2023-11-18 9:30:00  @CompanyXYZ  \n",
            "2  2023-11-18 10:15:00  @CompanyXYZ  \n",
            "3  2023-11-18 11:00:00  @CompanyXYZ  \n",
            "4  2023-11-18 11:45:00  @CompanyXYZ  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 52 entries, 0 to 51\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Tweet Text  52 non-null     object\n",
            " 1   Sentiment   52 non-null     object\n",
            " 2   Timestamp   52 non-null     object\n",
            " 3   User        52 non-null     object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.8+ KB\n",
            "None\n",
            "Positive    20\n",
            "Neutral     19\n",
            "Negative    13\n",
            "Name: Sentiment, dtype: int64\n",
            "(52, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exploring if there are any missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FYoqDh0DSGC",
        "outputId": "f291a848-3099-45de-853d-40464c60efd5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tweet Text    0\n",
              "Sentiment     0\n",
              "Timestamp     0\n",
              "User          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "7zh0QsNBFIOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(data['Sentiment'])\n",
        "encoded_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQyKDZD4EHGP",
        "outputId": "917672d8-349b-4f1a-a30e-95ab37480f10"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 1, 2, 0, 2, 2, 2, 1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1,\n",
              "       2, 0, 1, 2, 0, 2, 1, 0, 1, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0,\n",
              "       2, 1, 2, 1, 0, 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "where,\n",
        "\n",
        " 2 --> Positive\n",
        "\n",
        " 0 --> Negative\n",
        "\n",
        " 1 --> Neutral"
      ],
      "metadata": {
        "id": "95Tk5d_CEeSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Encoded Sentiment'] = encoded_labels"
      ],
      "metadata": {
        "id": "qDegwpE4V5d8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of sentiments column\n",
        "data['Encoded Sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCIkc7RyF8Yz",
        "outputId": "0ac0698e-0526-4bdc-c8f8-260d6b21c348"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    20\n",
              "1    19\n",
              "0    13\n",
              "Name: Encoded Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming: Stemming is a natural language processing technique that is used to reduce words to their base form, also known as the root form. The process of stemming is used to normalize text and make it easier to process.\n",
        "\n",
        "Ex: King,Emperor = kingdom\n",
        "\n",
        "similar meaning words"
      ],
      "metadata": {
        "id": "WEMYVjbBKGFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwT_LLJ8_V_9",
        "outputId": "eb5ce907-64a4-4da7-9fe3-9db8ef608a56"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since stopwords do not add much meaning to the contextual data we can exclude it from the tweets,it reduces the computational complexity\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbCvlTZo_h3_",
        "outputId": "0b81cd30-ff5f-4e97-f297-8cfc55f07846"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Port_stem = PorterStemmer()\n",
        "def stemming(content):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', content, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove mentions\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Remove hashtags\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Splitting the words in a tweet and convert it to a list\n",
        "    text = text.split()\n",
        "\n",
        "    #stemming for words that are not present in the stopwords\n",
        "    text = [Port_stem.stem(word) for word in text if not word in stopwords.words('english')]\n",
        "    text = ' '.join(text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "ff3DDo-4AWEo"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the stemming function to the 'Tweet Text' column\n",
        "data['Processed Tweet'] = data['Tweet Text'].apply(stemming)"
      ],
      "metadata": {
        "id": "fSPSU3KjSBJv"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Processed Tweet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idJSLNBKS0ea",
        "outputId": "dfeeb3db-257d-4a99-8c50-93f701a16b1b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0               team excit introduc latest product line\n",
            "1     apolog inconveni caus recent technic issu team...\n",
            "2                            neutral matter await updat\n",
            "3                    grate continu support loyal custom\n",
            "4               disappoint announc delay shipment order\n",
            "5     thrill posit feedback receiv recent product la...\n",
            "6                  strive provid better servic pass day\n",
            "7                                unexpect sale made day\n",
            "8            understand concern rais activ work address\n",
            "9                     team frustrat recur system glitch\n",
            "10                  thought everyon affect recent event\n",
            "11                delight see custom enjoy latest offer\n",
            "12           deepli regret inconveni caus stock shortag\n",
            "13                  neutral stanc ongo industri discuss\n",
            "14            look forward share excit news custom soon\n",
            "15                apolog confus caus recent price updat\n",
            "16                 posit vibe around celebr team achiev\n",
            "17                     pleas bear us work improv servic\n",
            "18                          disappoint neg rumor circul\n",
            "19              neutral feel toward recent market trend\n",
            "20                 eagerli anticip upcom product launch\n",
            "21                   commit resolv report issu promptli\n",
            "22            proud announc involv commun cleanup drive\n",
            "23               understand frustrat caus delay respons\n",
            "24                  neutral stanc recent industri regul\n",
            "25                   celebr posit review satisfi custom\n",
            "26      regret inconveni caus due recent server downtim\n",
            "27         team remain optimist despit current challeng\n",
            "28                activ look report issu immedi resolut\n",
            "29            regret oversight led recent product recal\n",
            "30                  neutral opinion chang consum prefer\n",
            "31            excit share upcom plan enhanc user experi\n",
            "32                         apolog delay respond inquiri\n",
            "33                  neutral stanc ongo technolog advanc\n",
            "34                    thrill part upcom industri confer\n",
            "35                        commit ensur satisfact servic\n",
            "36                           address report issu urgenc\n",
            "37               deepli concern recent environment issu\n",
            "38        excit announc particip chariti fundrais event\n",
            "39              work dilig resolv report technic glitch\n",
            "40            disappoint neg impact recent polici chang\n",
            "41              neutral opinion current econom forecast\n",
            "42                look forward bring innov solut custom\n",
            "43                 apolog inconveni caus server mainten\n",
            "44                 stay tune upcom surpris loyal custom\n",
            "45                commit address custom feedback improv\n",
            "46                             recent achiev motiv team\n",
            "47                   activ investig report qualiti issu\n",
            "48                         apolog recent deliveri delay\n",
            "49                 neutral stanc recent industri merger\n",
            "50                  excit introduc latest sustain initi\n",
            "51             take measur prevent futur servic disrupt\n",
            "Name: Processed Tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # seperating data and label\n",
        " X = data['Processed Tweet'].values\n",
        " Y = data['Encoded Sentiment'].values"
      ],
      "metadata": {
        "id": "DrqgD7uwTrnN"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdaLcnwaWhU3",
        "outputId": "20cccaa9-d53a-4896-9895-f0d535a1188a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['team excit introduc latest product line'\n",
            " 'apolog inconveni caus recent technic issu team work hard resolv'\n",
            " 'neutral matter await updat' 'grate continu support loyal custom'\n",
            " 'disappoint announc delay shipment order'\n",
            " 'thrill posit feedback receiv recent product launch'\n",
            " 'strive provid better servic pass day' 'unexpect sale made day'\n",
            " 'understand concern rais activ work address'\n",
            " 'team frustrat recur system glitch' 'thought everyon affect recent event'\n",
            " 'delight see custom enjoy latest offer'\n",
            " 'deepli regret inconveni caus stock shortag'\n",
            " 'neutral stanc ongo industri discuss'\n",
            " 'look forward share excit news custom soon'\n",
            " 'apolog confus caus recent price updat'\n",
            " 'posit vibe around celebr team achiev' 'pleas bear us work improv servic'\n",
            " 'disappoint neg rumor circul' 'neutral feel toward recent market trend'\n",
            " 'eagerli anticip upcom product launch'\n",
            " 'commit resolv report issu promptli'\n",
            " 'proud announc involv commun cleanup drive'\n",
            " 'understand frustrat caus delay respons'\n",
            " 'neutral stanc recent industri regul'\n",
            " 'celebr posit review satisfi custom'\n",
            " 'regret inconveni caus due recent server downtim'\n",
            " 'team remain optimist despit current challeng'\n",
            " 'activ look report issu immedi resolut'\n",
            " 'regret oversight led recent product recal'\n",
            " 'neutral opinion chang consum prefer'\n",
            " 'excit share upcom plan enhanc user experi'\n",
            " 'apolog delay respond inquiri' 'neutral stanc ongo technolog advanc'\n",
            " 'thrill part upcom industri confer' 'commit ensur satisfact servic'\n",
            " 'address report issu urgenc' 'deepli concern recent environment issu'\n",
            " 'excit announc particip chariti fundrais event'\n",
            " 'work dilig resolv report technic glitch'\n",
            " 'disappoint neg impact recent polici chang'\n",
            " 'neutral opinion current econom forecast'\n",
            " 'look forward bring innov solut custom'\n",
            " 'apolog inconveni caus server mainten'\n",
            " 'stay tune upcom surpris loyal custom'\n",
            " 'commit address custom feedback improv' 'recent achiev motiv team'\n",
            " 'activ investig report qualiti issu' 'apolog recent deliveri delay'\n",
            " 'neutral stanc recent industri merger'\n",
            " 'excit introduc latest sustain initi'\n",
            " 'take measur prevent futur servic disrupt']\n",
            "[2 0 1 2 0 2 2 2 1 0 1 2 0 1 2 0 2 1 0 1 2 1 2 0 1 2 0 2 1 0 1 2 0 1 2 2 1\n",
            " 1 2 1 0 1 2 0 2 1 2 1 0 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split:"
      ],
      "metadata": {
        "id": "yRsF5oYbXGSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,stratify=Y, random_state=2)"
      ],
      "metadata": {
        "id": "yHJxdXswW9rl"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape,X_train.shape,X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKLb3KW8YJOL",
        "outputId": "400ba47e-c641-44cb-a52c-3ea4abfc4a06"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(52,) (41,) (11,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBQwLzhslLnF",
        "outputId": "5e9a1197-65e0-4312-ede2-e831db032d49"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neutral stanc ongo industri discuss'\n",
            " 'regret oversight led recent product recal'\n",
            " 'thrill posit feedback receiv recent product launch'\n",
            " 'apolog recent deliveri delay' 'neutral feel toward recent market trend'\n",
            " 'look forward bring innov solut custom'\n",
            " 'commit resolv report issu promptli' 'commit ensur satisfact servic'\n",
            " 'neutral stanc recent industri regul'\n",
            " 'excit introduc latest sustain initi'\n",
            " 'understand frustrat caus delay respons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing the Tweets"
      ],
      "metadata": {
        "id": "LS3ZTBEBYqYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the tweets to numerical vectors\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform( X_test)"
      ],
      "metadata": {
        "id": "DztGqvgaYv3y"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doipxqKYcxRJ",
        "outputId": "dbca153d-7fe1-4a47-c41b-8515a99371f8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 66)\t0.386897389995149\n",
            "  (0, 43)\t0.5311822478475151\n",
            "  (0, 101)\t0.3336461419516689\n",
            "  (0, 21)\t0.4779309998040351\n",
            "  (0, 29)\t0.4779309998040351\n",
            "  (1, 27)\t0.31232936719346716\n",
            "  (1, 71)\t0.407121202763846\n",
            "  (1, 125)\t0.4524827971384037\n",
            "  (1, 136)\t0.3499723525224046\n",
            "  (1, 133)\t0.4524827971384037\n",
            "  (1, 121)\t0.4524827971384037\n",
            "  (2, 99)\t0.5119555968325987\n",
            "  (2, 105)\t0.39597152807493885\n",
            "  (2, 64)\t0.5119555968325987\n",
            "  (2, 1)\t0.42421703585773535\n",
            "  (2, 66)\t0.3728932678202036\n",
            "  (3, 137)\t0.4322507903420552\n",
            "  (3, 95)\t0.48041233262103067\n",
            "  (3, 12)\t0.34991809000724616\n",
            "  (3, 23)\t0.48041233262103067\n",
            "  (3, 7)\t0.37157442292050447\n",
            "  (3, 101)\t0.30175654772827065\n",
            "  (4, 35)\t0.419346659223958\n",
            "  (4, 115)\t0.34747934757123045\n",
            "  (4, 53)\t0.419346659223958\n",
            "  :\t:\n",
            "  (36, 109)\t0.4941328384799485\n",
            "  (36, 13)\t0.44459580960717976\n",
            "  (36, 92)\t0.44459580960717976\n",
            "  (36, 27)\t0.34107859509352234\n",
            "  (37, 81)\t0.43494692215139896\n",
            "  (37, 42)\t0.43494692215139896\n",
            "  (37, 113)\t0.43494692215139896\n",
            "  (37, 31)\t0.43494692215139896\n",
            "  (37, 67)\t0.3913433067612227\n",
            "  (37, 27)\t0.3002251087056032\n",
            "  (38, 48)\t0.5017203238518659\n",
            "  (38, 19)\t0.5017203238518659\n",
            "  (38, 2)\t0.415735876179153\n",
            "  (38, 59)\t0.45142264631810836\n",
            "  (38, 27)\t0.34631590913018356\n",
            "  (39, 22)\t0.4763107788987004\n",
            "  (39, 86)\t0.4763107788987004\n",
            "  (39, 132)\t0.4763107788987004\n",
            "  (39, 61)\t0.428560419138562\n",
            "  (39, 136)\t0.3684020804264275\n",
            "  (40, 126)\t0.48302957320111584\n",
            "  (40, 102)\t0.48302957320111584\n",
            "  (40, 51)\t0.48302957320111584\n",
            "  (40, 54)\t0.4346056514320796\n",
            "  (40, 128)\t0.33341448976123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOhuCfqAcvPY",
        "outputId": "c81df635-a45e-4506-8253-acd3c4220998"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 120)\t0.5069818783599955\n",
            "  (0, 82)\t0.5634699859930371\n",
            "  (0, 79)\t0.41041482053423456\n",
            "  (0, 61)\t0.5069818783599955\n",
            "  (1, 103)\t0.6340616221671181\n",
            "  (1, 101)\t0.4426417497136993\n",
            "  (1, 96)\t0.6340616221671181\n",
            "  (2, 132)\t0.44660514448538535\n",
            "  (2, 101)\t0.28052157999845617\n",
            "  (2, 96)\t0.40183278730880934\n",
            "  (2, 92)\t0.40183278730880934\n",
            "  (2, 68)\t0.44660514448538535\n",
            "  (2, 48)\t0.44660514448538535\n",
            "  (3, 101)\t0.4678731736848057\n",
            "  (3, 30)\t0.670204343957491\n",
            "  (3, 7)\t0.576125707364822\n",
            "  (4, 101)\t0.6530675193116966\n",
            "  (4, 79)\t0.7572996865310766\n",
            "  (5, 70)\t0.5950907073049084\n",
            "  (5, 50)\t0.6613959331137744\n",
            "  (5, 27)\t0.4565330981866521\n",
            "  (6, 107)\t0.5248967467892798\n",
            "  (6, 105)\t0.4512153826872965\n",
            "  (6, 66)\t0.42491736554646137\n",
            "  (6, 19)\t0.5833809356616327\n",
            "  (7, 115)\t0.6380403873591676\n",
            "  (7, 19)\t0.7700028987598445\n",
            "  (8, 120)\t0.5640917317905827\n",
            "  (8, 101)\t0.39379540162896653\n",
            "  (8, 79)\t0.45664671016759073\n",
            "  (8, 61)\t0.5640917317905827\n",
            "  (9, 67)\t0.5798476677309216\n",
            "  (9, 63)\t0.6444545084556984\n",
            "  (9, 46)\t0.49845267454206216\n",
            "  (10, 134)\t0.5471697058686555\n",
            "  (10, 51)\t0.5471697058686555\n",
            "  (10, 30)\t0.49231570830536686\n",
            "  (10, 12)\t0.3985421800951598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model using Logistic Regression"
      ],
      "metadata": {
        "id": "1iFRPgV7dAyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "e0y9Vm5Pc_xY",
        "outputId": "37102166-3c0c-4a1a-9035-acccfe3eaa65"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "GWNYfRMJd0rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # accuracy score on the training data\n",
        " X_train_prediction = model.predict(X_train)\n",
        " training_data_accuracy= accuracy_score(y_train,X_train_prediction)"
      ],
      "metadata": {
        "id": "3TRLa6n-dh_e"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score on the training data is :', training_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAkaI5uAeqHs",
        "outputId": "043f77fb-68ab-443c-dc61-e08f418c27ee"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score on the training data is : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # accuracy score on the testing data\n",
        " X_test_prediction = model.predict(X_test)\n",
        " testing_data_accuracy= accuracy_score(y_test,X_test_prediction)"
      ],
      "metadata": {
        "id": "a_jrbyrDe8ys"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score on the testing data is :', testing_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2DccNuJfmZb",
        "outputId": "d8a42d50-4b56-42a0-e85b-a8e905027fc6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score on the testing data is : 0.8181818181818182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Accuracy = 81.8%"
      ],
      "metadata": {
        "id": "-UnfsAsVgf4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the trained mode"
      ],
      "metadata": {
        "id": "dQu2tMwQg7Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'trained_model.sav'\n",
        "pickle.dump(model,open(filename,'wb'))"
      ],
      "metadata": {
        "id": "4ahe3DpUf9Jb"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the saved model for future predictions\n"
      ],
      "metadata": {
        "id": "_8qNPQxHhZlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the saved mode\n",
        "loaded_model = pickle.load(open('/content/trained_model.sav','rb'))"
      ],
      "metadata": {
        "id": "H_-FcexZhY9v"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[2]\n",
        "print(y_test[2])\n",
        "prediction_probabilities = loaded_model.predict_proba(X_new.reshape(1, -1))\n",
        "\n",
        "# Assuming prediction_probabilities is an array [[prob_negative, prob_neutral, prob_positive]]\n",
        "negative_threshold = 0.5\n",
        "neutral_threshold = 0.5\n",
        "\n",
        "if prediction_probabilities[0, 2] >= neutral_threshold:\n",
        "    print('Positive Tweet')\n",
        "elif prediction_probabilities[0, 1] >= neutral_threshold:\n",
        "    print('Neutral Tweet')\n",
        "else:\n",
        "    print('Negative Tweet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKxmx2-4piRy",
        "outputId": "d35cccfb-cafb-403a-961e-5880a3bc65b0"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Positive Tweet\n"
          ]
        }
      ]
    }
  ]
}